{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "from Networks import (\n",
    "    DummySteerModel,\n",
    "    SteerNN\n",
    ")\n",
    "import pickle\n",
    "import torchvision.models as models\n",
    "\n",
    "sys.path.append('./_out/steerings/')\n",
    "from steer001 import *\n",
    "from steer002 import *\n",
    "from steer003 import *\n",
    "from steer004 import *\n",
    "from steer005 import *\n",
    "from steer006 import *\n",
    "from steer007 import *\n",
    "from steer008 import *\n",
    "from steer009 import *\n",
    "from steer010 import *\n",
    "from steer011 import *\n",
    "from steer012 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 110)\n",
      "(12, 110)\n"
     ]
    }
   ],
   "source": [
    "#put the steering data all in an array\n",
    "steering001 = np.expand_dims(steering001,0)\n",
    "steering002 = np.expand_dims(steering002,0)\n",
    "steering003 = np.expand_dims(steering003,0)\n",
    "steering004 = np.expand_dims(steering004,0)\n",
    "steering005 = np.expand_dims(steering005,0)\n",
    "steering006 = np.expand_dims(steering006,0)\n",
    "steering007 = np.expand_dims(steering007,0)\n",
    "steering008 = np.expand_dims(steering008,0)\n",
    "steering009 = np.expand_dims(steering009,0)\n",
    "steering010 = np.expand_dims(steering010,0)\n",
    "steering011 = np.expand_dims(steering011,0)\n",
    "steering012 = np.expand_dims(steering012,0)\n",
    "print(steering001.shape)\n",
    "steering_data = np.append(steering001, steering002, axis=0)\n",
    "steering_data = np.append(steering_data, steering003, axis=0)\n",
    "steering_data = np.append(steering_data, steering004, axis=0)\n",
    "steering_data = np.append(steering_data, steering005, axis=0)\n",
    "steering_data = np.append(steering_data, steering006, axis=0)\n",
    "steering_data = np.append(steering_data, steering007, axis=0)\n",
    "steering_data = np.append(steering_data, steering008, axis=0)\n",
    "steering_data = np.append(steering_data, steering009, axis=0)\n",
    "steering_data = np.append(steering_data, steering010, axis=0)\n",
    "steering_data = np.append(steering_data, steering011, axis=0)\n",
    "steering_data = np.append(steering_data, steering012, axis=0)\n",
    "steering_data = steering_data *100\n",
    "print(steering_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_out/Dataset001/\n",
      "./_out/Dataset002/\n",
      "./_out/Dataset003/\n",
      "./_out/Dataset004/\n",
      "./_out/Dataset005/\n",
      "./_out/Dataset006/\n",
      "./_out/Dataset007/\n",
      "./_out/Dataset008/\n",
      "./_out/Dataset009/\n",
      "./_out/Dataset010/\n",
      "./_out/Dataset011/\n",
      "./_out/Dataset012/\n"
     ]
    }
   ],
   "source": [
    "#put the images and steeings into dicts\n",
    "list_of_image_data = []\n",
    "for j in range(1,13):\n",
    "    path_to_images = './_out/Dataset%03d/' %j\n",
    "    image_paths = os.listdir(path_to_images)\n",
    "    image_paths.sort()\n",
    "    #print(len(image_paths))     #number of images:110\n",
    "    print(path_to_images)\n",
    "    \n",
    "    i = 0\n",
    "    for im in image_paths:\n",
    "        image = torch.from_numpy(np.transpose(cv2.imread(path_to_images+im)[:,:,:3], (2, 0, 1)))\n",
    "        #img = (cv2.imread(path_to_images+im)[:,:,:3])/255\n",
    "        #cv2.imshow(\"image\", img)\n",
    "        #cv2.waitKey(10)\n",
    "        image = image.float()   #convert from int to float\n",
    "        imdict = {\n",
    "            'image': image,\n",
    "            'steer':steering_data[j-1][i]\n",
    "        }\n",
    "        list_of_image_data.append(imdict)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320\n",
      "torch.Size([3, 600, 800])\n",
      "7.332940000000001\n",
      "torch.Size([600, 800, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show an image and its corresponding steering\n",
    "print(len(list_of_image_data))\n",
    "print(list_of_image_data[0][\"image\"].shape)    #size of image: torch.Size([1, 600, 800])\n",
    "print(list_of_image_data[20][\"steer\"])\n",
    "#visualize the image\n",
    "image = (list_of_image_data[20][\"image\"].clone()/255 ).view(3, 600, 800)  \n",
    "image = np.transpose(image,(1,2,0))\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPATH_TO_IMAGES = \\'./_out/Dataset001/\\'\\nimage_paths = os.listdir(PATH_TO_IMAGES)\\nimage_paths.sort()\\nprint(len(image_paths))     #number of images:189\\n\\ni = 0\\n\\nfor im in image_paths:\\n    image = torch.from_numpy(np.transpose(cv2.imread(PATH_TO_IMAGES+im)[:,:,:1], (2, 0, 1)))\\n    imdict = {\\n        \\'image\\': image,\\n        \\'steer\\':steering001[i]\\n    }\\n    list_of_image_data.append(imdict)\\n    i+=1\\n    \\nprint(list_of_image_data[0][\"image\"].shape)    #size of image: torch.Size([1, 600, 800])\\nprint(list_of_image_data[0][\"steer\"])\\nimage = (list_of_image_data[0][\"image\"].clone() ).view(600, 800)  #visualize the image\\nplt.imshow(image,cmap=\\'gray\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PATH_TO_IMAGES = './_out/Dataset001/'\n",
    "image_paths = os.listdir(PATH_TO_IMAGES)\n",
    "image_paths.sort()\n",
    "print(len(image_paths))     #number of images:189\n",
    "\n",
    "i = 0\n",
    "\n",
    "for im in image_paths:\n",
    "    image = torch.from_numpy(np.transpose(cv2.imread(PATH_TO_IMAGES+im)[:,:,:1], (2, 0, 1)))\n",
    "    imdict = {\n",
    "        'image': image,\n",
    "        'steer':steering001[i]\n",
    "    }\n",
    "    list_of_image_data.append(imdict)\n",
    "    i+=1\n",
    "    \n",
    "print(list_of_image_data[0][\"image\"].shape)    #size of image: torch.Size([1, 600, 800])\n",
    "print(list_of_image_data[0][\"steer\"])\n",
    "image = (list_of_image_data[0][\"image\"].clone() ).view(600, 800)  #visualize the image\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_in_range(lst,small,large):\n",
    "    length = len(lst)\n",
    "    num = 0\n",
    "    for i in range(length):\n",
    "        if (lst[i]['steer']>= small) & (lst[i]['steer']<= large):\n",
    "            num += 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turning left 425\n",
      "going straight 460\n",
      "turning right 435\n"
     ]
    }
   ],
   "source": [
    "#list_of_image_data.sort(key=lambda k: (k.get('steer', 0))) #sort the list according to 'steer'\n",
    "print(\"turning left\", num_in_range(list_of_image_data,-100,-4))\n",
    "print(\"going straight\", num_in_range(list_of_image_data,-4,4))\n",
    "print(\"turning right\", num_in_range(list_of_image_data,4,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8715229999999999\n",
      "length of training dataset 1100\n",
      "length of validation dataset 220\n",
      "-0.8715229999999999\n",
      "-0.48025362199999994\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(list_of_image_data)\n",
    "print(list_of_image_data[0]['steer'])\n",
    "train_dataset = list_of_image_data[:1100]\n",
    "val_dataset = list_of_image_data[1100:]\n",
    "print(\"length of training dataset\", len(train_dataset))\n",
    "print(\"length of validation dataset\", len(val_dataset))\n",
    "print(train_dataset[0]['steer'])\n",
    "print(val_dataset[0]['steer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"learning_rate\": 0.9e-3,\n",
    "    \"batch_size\": 50,\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4498]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with one image before training\n",
    "steer_model = SteerNN(hparams)\n",
    "#print(list_of_image_data[0]['image'])\n",
    "steer_model(list_of_image_data[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "/home/melina/anaconda3/envs/i2dl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/melina/anaconda3/envs/i2dl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(114.0325, dtype=torch.float64)\n",
      "validation loss tensor(197.2120, dtype=torch.float64)\n",
      "tensor(155.6223, dtype=torch.float64)\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melina/anaconda3/envs/i2dl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339586be1867437494e8b261cf83a715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss tensor(92.6353, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2768282.9599, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(62582.8616, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8788.1426, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(13441.8247, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(13257.0844, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8744.2326, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3410.6845, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(282.2092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(766.9932, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2984.7277, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3977.9552, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3088.4918, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1905.3091, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(739.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(116.5297, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(150.5692, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(595.3445, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1141.4727, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1410.4455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1484.1419, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1041.8375, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(430.2158, dtype=torch.float64)\n",
      "validation loss tensor(437.2962, dtype=torch.float64)\n",
      "validation loss tensor(444.2083, dtype=torch.float64)\n",
      "validation loss tensor(504.1047, dtype=torch.float64)\n",
      "validation loss tensor(288.8313, dtype=torch.float64)\n",
      "tensor(420.9313, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melina/anaconda3/envs/i2dl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Did not find hyperparameters at model hparams. Saving checkpoint without hyperparameters.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss tensor(441.1563, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(58.1614, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(189.2446, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(512.8633, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(425.3888, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(278.2944, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(88.6588, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(35.8791, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(33.4942, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(23.5484, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(42.1547, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(55.0662, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(76.3645, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(57.5443, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(43.6048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(27.7272, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(20.0319, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(36.8548, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(27.1459, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(33.2362, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(25.8937, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(33.8480, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(38.0881, dtype=torch.float64)\n",
      "validation loss tensor(40.3160, dtype=torch.float64)\n",
      "validation loss tensor(30.6191, dtype=torch.float64)\n",
      "validation loss tensor(34.1338, dtype=torch.float64)\n",
      "validation loss tensor(10.9479, dtype=torch.float64)\n",
      "tensor(30.8210, dtype=torch.float64)\n",
      "training loss tensor(27.7340, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(28.3007, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(22.5039, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(22.1867, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(12.3363, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(16.3201, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(17.3330, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(14.5650, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(23.6848, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.6261, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(12.0749, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(11.4053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(12.6328, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.4425, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(17.5750, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(11.0299, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(16.6725, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(15.9579, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(12.2045, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(10.0623, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(12.9005, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(10.9107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(11.5597, dtype=torch.float64)\n",
      "validation loss tensor(22.6666, dtype=torch.float64)\n",
      "validation loss tensor(8.5416, dtype=torch.float64)\n",
      "validation loss tensor(18.0525, dtype=torch.float64)\n",
      "validation loss tensor(1.5231, dtype=torch.float64)\n",
      "tensor(12.4687, dtype=torch.float64)\n",
      "training loss tensor(18.3679, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(10.3241, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(9.7025, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(11.1664, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(9.0939, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(9.0155, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.0129, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.8421, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.3933, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.5373, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(11.9152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.3822, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(10.0609, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(10.1536, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.0906, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(9.3881, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.4784, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.8153, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.2692, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.5798, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.9180, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(11.3235, dtype=torch.float64)\n",
      "validation loss tensor(13.6063, dtype=torch.float64)\n",
      "validation loss tensor(7.3046, dtype=torch.float64)\n",
      "validation loss tensor(9.6970, dtype=torch.float64)\n",
      "validation loss tensor(1.0574, dtype=torch.float64)\n",
      "tensor(8.5978, dtype=torch.float64)\n",
      "training loss tensor(3.8812, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.4155, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.7638, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.3973, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.4932, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(9.2989, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.1590, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.8892, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.8848, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.2838, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.2531, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2510, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.4671, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.0581, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.6219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.6378, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4118, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.4217, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(8.8386, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.8250, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.9685, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.4700, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(8.8663, dtype=torch.float64)\n",
      "validation loss tensor(11.7703, dtype=torch.float64)\n",
      "validation loss tensor(5.4148, dtype=torch.float64)\n",
      "validation loss tensor(8.2450, dtype=torch.float64)\n",
      "validation loss tensor(0.7928, dtype=torch.float64)\n",
      "tensor(7.0178, dtype=torch.float64)\n",
      "training loss tensor(4.7895, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.9563, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.6699, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.1392, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.1576, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.8867, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.1825, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.4921, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.0199, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.9885, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.9716, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.7535, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(7.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.2412, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.3047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.9195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4787, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.5085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.5414, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4108, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.8710, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(8.7633, dtype=torch.float64)\n",
      "validation loss tensor(9.2077, dtype=torch.float64)\n",
      "validation loss tensor(5.0922, dtype=torch.float64)\n",
      "validation loss tensor(6.1942, dtype=torch.float64)\n",
      "validation loss tensor(1.0387, dtype=torch.float64)\n",
      "tensor(6.0592, dtype=torch.float64)\n",
      "training loss tensor(4.9401, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(6.7624, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.3118, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4412, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.4257, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.0507, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.1679, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.2582, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.3193, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5763, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5191, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.2296, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.0609, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.3822, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.8151, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3528, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.2811, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.4170, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7755, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.6936, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3326, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.2195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(7.8508, dtype=torch.float64)\n",
      "validation loss tensor(8.5479, dtype=torch.float64)\n",
      "validation loss tensor(4.1747, dtype=torch.float64)\n",
      "validation loss tensor(6.0491, dtype=torch.float64)\n",
      "validation loss tensor(0.6535, dtype=torch.float64)\n",
      "tensor(5.4552, dtype=torch.float64)\n",
      "training loss tensor(4.3914, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2253, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.4631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7427, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3364, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2514, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4467, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.3403, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5339, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.8096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2895, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3394, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.7244, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4808, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.7542, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2411, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2299, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.9504, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4603, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(7.7214, dtype=torch.float64)\n",
      "validation loss tensor(7.1631, dtype=torch.float64)\n",
      "validation loss tensor(4.2460, dtype=torch.float64)\n",
      "validation loss tensor(4.7677, dtype=torch.float64)\n",
      "validation loss tensor(0.7315, dtype=torch.float64)\n",
      "tensor(4.9259, dtype=torch.float64)\n",
      "training loss tensor(1.8080, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(5.0573, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.6267, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5934, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.9098, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4342, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(4.4100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9106, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3754, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9448, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4260, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.0029, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5995, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8211, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2136, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7313, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7228, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.1543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.6901, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.2196, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5228, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(7.8757, dtype=torch.float64)\n",
      "validation loss tensor(6.6771, dtype=torch.float64)\n",
      "validation loss tensor(4.2654, dtype=torch.float64)\n",
      "validation loss tensor(4.5121, dtype=torch.float64)\n",
      "validation loss tensor(0.4930, dtype=torch.float64)\n",
      "tensor(4.7647, dtype=torch.float64)\n",
      "training loss tensor(2.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5687, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.6952, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4482, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7894, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.8663, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3223, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7132, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.9481, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.6894, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.5776, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7584, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4285, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.3325, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0572, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.6158, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.0195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5807, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.9081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.8499, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.6091, dtype=torch.float64)\n",
      "validation loss tensor(6.2734, dtype=torch.float64)\n",
      "validation loss tensor(3.5859, dtype=torch.float64)\n",
      "validation loss tensor(4.1389, dtype=torch.float64)\n",
      "validation loss tensor(0.5248, dtype=torch.float64)\n",
      "tensor(4.2264, dtype=torch.float64)\n",
      "training loss tensor(3.2344, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7142, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9414, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.8479, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9976, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8146, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5806, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4712, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5731, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7772, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7696, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.1826, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2977, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9997, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.1589, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4622, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5097, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.7055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2931, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(7.8883, dtype=torch.float64)\n",
      "validation loss tensor(5.5894, dtype=torch.float64)\n",
      "validation loss tensor(4.1506, dtype=torch.float64)\n",
      "validation loss tensor(3.7872, dtype=torch.float64)\n",
      "validation loss tensor(1.2491, dtype=torch.float64)\n",
      "tensor(4.5329, dtype=torch.float64)\n",
      "training loss tensor(2.1387, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.9444, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.5202, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4247, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0361, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4521, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.6960, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7778, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7147, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4531, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9396, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2200, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7715, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2417, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4102, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4091, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0189, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2312, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.4413, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9677, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0821, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.9730, dtype=torch.float64)\n",
      "validation loss tensor(5.3755, dtype=torch.float64)\n",
      "validation loss tensor(3.4931, dtype=torch.float64)\n",
      "validation loss tensor(3.6485, dtype=torch.float64)\n",
      "validation loss tensor(0.5133, dtype=torch.float64)\n",
      "tensor(4.0007, dtype=torch.float64)\n",
      "training loss tensor(1.4290, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.1558, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3658, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4293, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7346, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7328, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2692, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2563, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9165, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1724, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3221, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.4107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5256, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5387, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8506, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2784, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3439, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.6438, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9652, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7208, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2703, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.6800, dtype=torch.float64)\n",
      "validation loss tensor(5.3109, dtype=torch.float64)\n",
      "validation loss tensor(3.3262, dtype=torch.float64)\n",
      "validation loss tensor(3.6071, dtype=torch.float64)\n",
      "validation loss tensor(0.5080, dtype=torch.float64)\n",
      "tensor(3.8864, dtype=torch.float64)\n",
      "training loss tensor(0.8822, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8976, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(3.3175, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0427, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8561, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6699, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8988, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4177, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4448, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4271, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.2911, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5636, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1530, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0811, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6580, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.3479, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2001, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4270, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6388, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.5357, dtype=torch.float64)\n",
      "validation loss tensor(5.4166, dtype=torch.float64)\n",
      "validation loss tensor(3.1683, dtype=torch.float64)\n",
      "validation loss tensor(3.6998, dtype=torch.float64)\n",
      "validation loss tensor(0.4963, dtype=torch.float64)\n",
      "tensor(3.8633, dtype=torch.float64)\n",
      "training loss tensor(1.0782, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6985, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6135, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8465, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1831, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8486, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0553, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2774, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7860, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7781, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8229, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0343, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3346, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3857, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(2.0426, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7957, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9576, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9333, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0907, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.9854, dtype=torch.float64)\n",
      "validation loss tensor(4.6616, dtype=torch.float64)\n",
      "validation loss tensor(3.1712, dtype=torch.float64)\n",
      "validation loss tensor(3.2497, dtype=torch.float64)\n",
      "validation loss tensor(0.7480, dtype=torch.float64)\n",
      "tensor(3.5632, dtype=torch.float64)\n",
      "training loss tensor(1.0301, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6265, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4562, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3568, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4407, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8019, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2350, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4935, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7947, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8126, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9488, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0610, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9663, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5425, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6071, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7662, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.5049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.8416, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0920, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6866, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.2362, dtype=torch.float64)\n",
      "validation loss tensor(4.8302, dtype=torch.float64)\n",
      "validation loss tensor(2.8945, dtype=torch.float64)\n",
      "validation loss tensor(3.4797, dtype=torch.float64)\n",
      "validation loss tensor(0.4915, dtype=torch.float64)\n",
      "tensor(3.5864, dtype=torch.float64)\n",
      "training loss tensor(1.6200, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2717, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9526, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2017, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.9972, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5236, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0674, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6241, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2498, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1821, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8792, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0176, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1910, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9426, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9203, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7841, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6710, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9780, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8544, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6278, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.0536, dtype=torch.float64)\n",
      "validation loss tensor(4.9037, dtype=torch.float64)\n",
      "validation loss tensor(2.9860, dtype=torch.float64)\n",
      "validation loss tensor(3.3861, dtype=torch.float64)\n",
      "validation loss tensor(0.6717, dtype=torch.float64)\n",
      "tensor(3.6002, dtype=torch.float64)\n",
      "training loss tensor(0.6250, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3990, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0088, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6506, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2860, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3422, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7187, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6657, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4805, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8837, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0122, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9295, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3770, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1942, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9913, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8776, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.7138, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0791, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.9513, dtype=torch.float64)\n",
      "validation loss tensor(4.8905, dtype=torch.float64)\n",
      "validation loss tensor(2.9166, dtype=torch.float64)\n",
      "validation loss tensor(3.4740, dtype=torch.float64)\n",
      "validation loss tensor(0.2650, dtype=torch.float64)\n",
      "tensor(3.4995, dtype=torch.float64)\n",
      "training loss tensor(1.0086, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2135, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6887, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1664, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6945, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4872, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5802, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7792, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8429, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3783, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9645, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6132, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7140, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8793, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.4008, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.3613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5857, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9342, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6157, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9702, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0659, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7983, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.5843, dtype=torch.float64)\n",
      "validation loss tensor(4.6537, dtype=torch.float64)\n",
      "validation loss tensor(2.7832, dtype=torch.float64)\n",
      "validation loss tensor(3.2662, dtype=torch.float64)\n",
      "validation loss tensor(0.5145, dtype=torch.float64)\n",
      "tensor(3.3604, dtype=torch.float64)\n",
      "training loss tensor(0.3337, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7539, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7933, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7368, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6956, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8939, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4654, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7640, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1921, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9956, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8430, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6144, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0184, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4816, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4836, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5885, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6917, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8517, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7592, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.6603, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8335, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.8212, dtype=torch.float64)\n",
      "validation loss tensor(4.6522, dtype=torch.float64)\n",
      "validation loss tensor(2.8100, dtype=torch.float64)\n",
      "validation loss tensor(3.5835, dtype=torch.float64)\n",
      "validation loss tensor(0.3918, dtype=torch.float64)\n",
      "tensor(3.4517, dtype=torch.float64)\n",
      "training loss tensor(0.8441, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2720, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5774, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5337, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6939, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9041, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7857, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0504, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6993, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6737, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8983, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4348, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6140, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9700, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4383, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8375, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6420, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8640, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2625, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3458, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.6882, dtype=torch.float64)\n",
      "validation loss tensor(4.5584, dtype=torch.float64)\n",
      "validation loss tensor(2.7237, dtype=torch.float64)\n",
      "validation loss tensor(3.1983, dtype=torch.float64)\n",
      "validation loss tensor(0.4445, dtype=torch.float64)\n",
      "tensor(3.3226, dtype=torch.float64)\n",
      "training loss tensor(1.0234, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0346, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2560, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4745, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8928, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5624, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4458, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6832, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7271, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9511, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2961, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3213, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8595, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5460, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5036, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9835, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4446, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8586, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4644, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.7216, dtype=torch.float64)\n",
      "validation loss tensor(4.2548, dtype=torch.float64)\n",
      "validation loss tensor(2.6586, dtype=torch.float64)\n",
      "validation loss tensor(2.9703, dtype=torch.float64)\n",
      "validation loss tensor(0.4864, dtype=torch.float64)\n",
      "tensor(3.2183, dtype=torch.float64)\n",
      "training loss tensor(0.3838, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4462, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4192, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3274, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6026, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5244, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6808, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3276, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2397, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6025, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6587, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.2058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6106, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4179, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3360, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5867, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6553, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8996, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4102, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3582, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3816, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.7176, dtype=torch.float64)\n",
      "validation loss tensor(4.4609, dtype=torch.float64)\n",
      "validation loss tensor(2.7577, dtype=torch.float64)\n",
      "validation loss tensor(3.2899, dtype=torch.float64)\n",
      "validation loss tensor(0.3200, dtype=torch.float64)\n",
      "tensor(3.3092, dtype=torch.float64)\n",
      "training loss tensor(0.5901, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2467, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.7623, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6845, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3180, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4141, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3879, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2476, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5497, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3907, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3661, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5495, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4235, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3730, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5706, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3633, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4880, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5266, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3510, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(1.0379, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5304, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(5.7288, dtype=torch.float64)\n",
      "validation loss tensor(4.3720, dtype=torch.float64)\n",
      "validation loss tensor(2.7342, dtype=torch.float64)\n",
      "validation loss tensor(3.0915, dtype=torch.float64)\n",
      "validation loss tensor(0.4672, dtype=torch.float64)\n",
      "tensor(3.2787, dtype=torch.float64)\n",
      "training loss tensor(0.3427, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6122, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3527, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2620, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6174, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3212, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.2794, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5970, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6364, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.9216, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4868, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.5105, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.3145, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4610, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4331, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.8158, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4366, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.6958, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.1638, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "training loss tensor(0.4220, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss tensor(6.0549, dtype=torch.float64)\n",
      "validation loss tensor(4.3174, dtype=torch.float64)\n",
      "validation loss tensor(2.7775, dtype=torch.float64)\n",
      "validation loss tensor(3.2600, dtype=torch.float64)\n",
      "validation loss tensor(0.4343, dtype=torch.float64)\n",
      "tensor(3.3688, dtype=torch.float64)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "steer_model = SteerNN(hparams, train_dataset, val_dataset)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    weights_summary=None,\n",
    "    max_epochs=25,\n",
    "    progress_bar_refresh_rate=1, # to prevent notebook crashes in Google Colab environments    \n",
    ")\n",
    "\n",
    "trainer.fit(steer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031213587149977684\n",
      "0.02858242\n"
     ]
    }
   ],
   "source": [
    "#test with one image after training\n",
    "steer_test = steer_model(list_of_image_data[1000]['image'])/100\n",
    "steer_test = float(steer_test)\n",
    "print(steer_test)\n",
    "print(list_of_image_data[1000]['steer']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/depth_camera.p'\n",
    "torch.save(steer_model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0312]], grad_fn=<DivBackward0>)\n",
      "0.02858242\n"
     ]
    }
   ],
   "source": [
    "PATH = 'models/depth_camera.p'\n",
    "steer_model2 = SteerNN(None)\n",
    "steer_model2.load_state_dict(torch.load(PATH))\n",
    "print(steer_model2(list_of_image_data[1000]['image'])/100)\n",
    "print(list_of_image_data[1000]['steer']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
